{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNMXd27T0U3pFqWhQOsUWwm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Geraldoviananeto/Analisador-Lexico/blob/main/Analisador_Lexico.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def lexical_analyzer():\n",
        "    # Definir os padrões de tokens\n",
        "    token_patterns = {\n",
        "        'int': r'\\b\\d+\\b',\n",
        "        'float': r'\\b\\d+\\.\\d+\\b',\n",
        "        'identifier': r'\\b[a-zA-Z_][a-zA-Z0-9_]*\\b',\n",
        "        'keyword': r'\\b(if|else|while|for|return|int|float|string|void)\\b',\n",
        "        'string': r'\"[^\"]*\"',\n",
        "        'symbol': r'[!@#$%^&*()_+\\-=\\[\\]{};:\"\\\\|,.<>\\/?]'\n",
        "    }\n",
        "\n",
        "    # Ler a entrada do usuário\n",
        "    input_text = input(\"Digite o texto a ser analisado (ou 'sair' para encerrar):\\n\")\n",
        "\n",
        "    # Sair do loop se o usuário digitar 'sair'\n",
        "    if input_text.lower() == 'sair':\n",
        "        return \"Encerrando a análise léxica.\"\n",
        "\n",
        "    # Inicializar a lista de tokens\n",
        "    tokens = []\n",
        "\n",
        "    # Percorrer o texto de entrada e identificar os tokens\n",
        "    for line in input_text.split('\\n'):\n",
        "        for token_type, pattern in token_patterns.items():\n",
        "            matches = re.findall(pattern, line)\n",
        "            for match in matches:\n",
        "                tokens.append({\n",
        "                    'Token': match,\n",
        "                    'Categoria': token_type\n",
        "                })\n",
        "\n",
        "    # Formatar a saída\n",
        "    output = ''\n",
        "    for token in tokens:\n",
        "        output += f\"<Token: '{token['Token']}', Categoria: {token['Categoria']}>\\n\"\n",
        "\n",
        "    return output\n",
        "\n",
        "# Executar o analisador léxico em loop\n",
        "while True:\n",
        "    result = lexical_analyzer()\n",
        "    print(result)\n",
        "    if result.startswith(\"Encerrando\"):\n",
        "        break\n",
        "    print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NGT12y0aV2cl",
        "outputId": "9c0efbba-f920-4c1c-91c1-740d696855dd"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Digite o texto a ser analisado (ou 'sair' para encerrar):\n",
            "sair\n",
            "Encerrando a análise léxica.\n"
          ]
        }
      ]
    }
  ]
}